{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303bd350",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Building the CNN\n",
    "#importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18832ae4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d51cf42",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution Layer\n",
    "classifier.add(Convolution2D(32, 3,  3, input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a3007a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d13769",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding second convolution layer\n",
    "classifier.add(Convolution2D(32, 3,  3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7a671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Adding 3rd Concolution Layer\n",
    "classifier.add(Convolution2D(64, 3,  3 , activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de2dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7ed8c3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Step 4 - Full Connection\n",
    "classifier.add(Dense(256, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0db3b7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compiling The CNN\n",
    "classifier.compile(\n",
    "              optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e8970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2 Fittting the CNN to the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4930d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3001 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        'Data/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bad8e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "        'Data/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bbe4a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programming\\anaconda3\\envs\\crop\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 446s 4s/step - loss: 2.1872 - acc: 0.1794 - val_loss: 1.9164 - val_acc: 0.3260\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 436s 4s/step - loss: 1.8643 - acc: 0.3441 - val_loss: 1.7239 - val_acc: 0.3940\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 436s 4s/step - loss: 1.6348 - acc: 0.4120 - val_loss: 1.3967 - val_acc: 0.5340\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 435s 4s/step - loss: 1.4622 - acc: 0.4813 - val_loss: 1.1824 - val_acc: 0.6260\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 435s 4s/step - loss: 1.2542 - acc: 0.5565 - val_loss: 1.0237 - val_acc: 0.6840\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 436s 4s/step - loss: 1.0746 - acc: 0.6339 - val_loss: 0.8509 - val_acc: 0.7320\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 394s 4s/step - loss: 0.9178 - acc: 0.6883 - val_loss: 0.6737 - val_acc: 0.7800\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 364s 4s/step - loss: 0.7644 - acc: 0.7407 - val_loss: 0.5472 - val_acc: 0.8300\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.6420 - acc: 0.7784 - val_loss: 0.4515 - val_acc: 0.8900\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 365s 4s/step - loss: 0.5109 - acc: 0.8236 - val_loss: 0.3871 - val_acc: 0.9040\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 366s 4s/step - loss: 0.4530 - acc: 0.8514 - val_loss: 0.2895 - val_acc: 0.9220\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 366s 4s/step - loss: 0.3849 - acc: 0.8621 - val_loss: 0.3391 - val_acc: 0.9180\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.3327 - acc: 0.8907 - val_loss: 0.3879 - val_acc: 0.9060\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 366s 4s/step - loss: 0.2989 - acc: 0.8962 - val_loss: 0.3365 - val_acc: 0.9320\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 366s 4s/step - loss: 0.2788 - acc: 0.9008 - val_loss: 0.3381 - val_acc: 0.9480\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.2460 - acc: 0.9189 - val_loss: 0.2908 - val_acc: 0.9460\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.2505 - acc: 0.9087 - val_loss: 0.3091 - val_acc: 0.9420\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1862 - acc: 0.9346 - val_loss: 0.3461 - val_acc: 0.9440\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1831 - acc: 0.9354 - val_loss: 0.3540 - val_acc: 0.9340\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.1950 - acc: 0.9283 - val_loss: 0.3086 - val_acc: 0.9540\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1715 - acc: 0.9415 - val_loss: 0.3712 - val_acc: 0.9440\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 366s 4s/step - loss: 0.1681 - acc: 0.9421 - val_loss: 0.3391 - val_acc: 0.9480\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1641 - acc: 0.9406 - val_loss: 0.2849 - val_acc: 0.9520\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1646 - acc: 0.9394 - val_loss: 0.3827 - val_acc: 0.9440\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1437 - acc: 0.9480 - val_loss: 0.3582 - val_acc: 0.9440\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 431s 4s/step - loss: 0.1453 - acc: 0.9405 - val_loss: 0.3470 - val_acc: 0.9500\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1426 - acc: 0.9495 - val_loss: 0.3307 - val_acc: 0.9480\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1254 - acc: 0.9533 - val_loss: 0.3658 - val_acc: 0.9500\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1211 - acc: 0.9530 - val_loss: 0.4335 - val_acc: 0.9460\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1633 - acc: 0.9353 - val_loss: 0.3480 - val_acc: 0.9440\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1290 - acc: 0.9515 - val_loss: 0.4274 - val_acc: 0.9400\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1137 - acc: 0.9598 - val_loss: 0.3599 - val_acc: 0.9440\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1329 - acc: 0.9522 - val_loss: 0.4118 - val_acc: 0.9460\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 367s 4s/step - loss: 0.1369 - acc: 0.9474 - val_loss: 0.4822 - val_acc: 0.9320\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1384 - acc: 0.9504 - val_loss: 0.3407 - val_acc: 0.9500\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1132 - acc: 0.9552 - val_loss: 0.4146 - val_acc: 0.9500\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1265 - acc: 0.9486 - val_loss: 0.4226 - val_acc: 0.9340\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.1094 - acc: 0.9564 - val_loss: 0.3791 - val_acc: 0.9440\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.1040 - acc: 0.9570 - val_loss: 0.3654 - val_acc: 0.9480\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.1338 - acc: 0.9533 - val_loss: 0.3846 - val_acc: 0.9520\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.1239 - acc: 0.9524 - val_loss: 0.4088 - val_acc: 0.9480\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.1238 - acc: 0.9594 - val_loss: 0.3597 - val_acc: 0.9460\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 381s 4s/step - loss: 0.1188 - acc: 0.9517 - val_loss: 0.3616 - val_acc: 0.9460\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 386s 4s/step - loss: 0.1248 - acc: 0.9562 - val_loss: 0.4460 - val_acc: 0.9480\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 374s 4s/step - loss: 0.1152 - acc: 0.9518 - val_loss: 0.3388 - val_acc: 0.9540\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 372s 4s/step - loss: 0.0948 - acc: 0.9599 - val_loss: 0.3787 - val_acc: 0.9560\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.1145 - acc: 0.9534 - val_loss: 0.3875 - val_acc: 0.9520\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.0986 - acc: 0.9640 - val_loss: 0.3447 - val_acc: 0.9460\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0933 - acc: 0.9565 - val_loss: 0.4794 - val_acc: 0.9420\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0963 - acc: 0.9584 - val_loss: 0.4622 - val_acc: 0.9340\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0991 - acc: 0.9591 - val_loss: 0.4448 - val_acc: 0.9460\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.0876 - acc: 0.9634 - val_loss: 0.4475 - val_acc: 0.9480\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0978 - acc: 0.9605 - val_loss: 0.4326 - val_acc: 0.9420\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0967 - acc: 0.9597 - val_loss: 0.4670 - val_acc: 0.9460\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 372s 4s/step - loss: 0.1050 - acc: 0.9621 - val_loss: 0.4337 - val_acc: 0.9360\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0972 - acc: 0.9603 - val_loss: 0.3593 - val_acc: 0.9400\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0885 - acc: 0.9648 - val_loss: 0.4575 - val_acc: 0.9500\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0881 - acc: 0.9641 - val_loss: 0.5297 - val_acc: 0.9500\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0867 - acc: 0.9624 - val_loss: 0.5055 - val_acc: 0.9400\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.0829 - acc: 0.9644 - val_loss: 0.4210 - val_acc: 0.9500\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0908 - acc: 0.9587 - val_loss: 0.4187 - val_acc: 0.9520\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0857 - acc: 0.9605 - val_loss: 0.3994 - val_acc: 0.9480\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 420s 4s/step - loss: 0.0983 - acc: 0.9593 - val_loss: 0.4120 - val_acc: 0.9520\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 407s 4s/step - loss: 0.1475 - acc: 0.9440 - val_loss: 0.3545 - val_acc: 0.9500\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 425s 4s/step - loss: 0.0937 - acc: 0.9591 - val_loss: 0.4377 - val_acc: 0.9460\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 426s 4s/step - loss: 0.0870 - acc: 0.9647 - val_loss: 0.4391 - val_acc: 0.9460\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 392s 4s/step - loss: 0.0899 - acc: 0.9606 - val_loss: 0.4463 - val_acc: 0.9320\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 372s 4s/step - loss: 0.0797 - acc: 0.9626 - val_loss: 0.4156 - val_acc: 0.9460\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0748 - acc: 0.9671 - val_loss: 0.4310 - val_acc: 0.9520\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0863 - acc: 0.9606 - val_loss: 0.4782 - val_acc: 0.9380\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 368s 4s/step - loss: 0.0684 - acc: 0.9709 - val_loss: 0.5353 - val_acc: 0.9420\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0803 - acc: 0.9649 - val_loss: 0.4547 - val_acc: 0.9540\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0824 - acc: 0.9619 - val_loss: 0.5001 - val_acc: 0.9460\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0827 - acc: 0.9637 - val_loss: 0.4711 - val_acc: 0.9460\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0938 - acc: 0.9586 - val_loss: 0.3986 - val_acc: 0.9520\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 372s 4s/step - loss: 0.1018 - acc: 0.9584 - val_loss: 0.4331 - val_acc: 0.9500\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0880 - acc: 0.9626 - val_loss: 0.4354 - val_acc: 0.9520\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0864 - acc: 0.9672 - val_loss: 0.4476 - val_acc: 0.9480\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0857 - acc: 0.9612 - val_loss: 0.4247 - val_acc: 0.9420\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0646 - acc: 0.9718 - val_loss: 0.4508 - val_acc: 0.9480\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0944 - acc: 0.9577 - val_loss: 0.4396 - val_acc: 0.9440\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0796 - acc: 0.9652 - val_loss: 0.4382 - val_acc: 0.9500\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 373s 4s/step - loss: 0.0971 - acc: 0.9596 - val_loss: 0.4633 - val_acc: 0.9380\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 372s 4s/step - loss: 0.0942 - acc: 0.9637 - val_loss: 0.4358 - val_acc: 0.9540\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0869 - acc: 0.9609 - val_loss: 0.5012 - val_acc: 0.9400\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0978 - acc: 0.9630 - val_loss: 0.4649 - val_acc: 0.9480\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.1006 - acc: 0.9584 - val_loss: 0.6216 - val_acc: 0.9240\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0975 - acc: 0.9622 - val_loss: 0.5011 - val_acc: 0.9500\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.1009 - acc: 0.9612 - val_loss: 0.4843 - val_acc: 0.9440\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0935 - acc: 0.9623 - val_loss: 0.4315 - val_acc: 0.9440\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 369s 4s/step - loss: 0.0859 - acc: 0.9647 - val_loss: 0.4296 - val_acc: 0.9400\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 370s 4s/step - loss: 0.0818 - acc: 0.9665 - val_loss: 0.4861 - val_acc: 0.9500\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 372s 4s/step - loss: 0.0916 - acc: 0.9628 - val_loss: 0.4802 - val_acc: 0.9500\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0683 - acc: 0.9673 - val_loss: 0.4087 - val_acc: 0.9520\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 385s 4s/step - loss: 0.0821 - acc: 0.9662 - val_loss: 0.4696 - val_acc: 0.9480\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 375s 4s/step - loss: 0.0798 - acc: 0.9659 - val_loss: 0.4461 - val_acc: 0.9460\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 409s 4s/step - loss: 0.0955 - acc: 0.9594 - val_loss: 0.5097 - val_acc: 0.9300\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 405s 4s/step - loss: 0.0843 - acc: 0.9673 - val_loss: 0.4344 - val_acc: 0.9520\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 419s 4s/step - loss: 0.0750 - acc: 0.9677 - val_loss: 0.4227 - val_acc: 0.9440\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 0.0797 - acc: 0.9634 - val_loss: 0.5401 - val_acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=100,\n",
    "        validation_data = test_set,\n",
    "        validation_steps = 6500\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81af8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "import h5py\n",
    "classifier.save('Trained_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
